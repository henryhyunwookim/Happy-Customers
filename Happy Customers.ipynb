{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, RandomizedSearchCV\n",
    "from sklearn.feature_selection import mutual_info_classif, RFE, SequentialFeatureSelector\n",
    "from skfeature.function.similarity_based import fisher_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=(FutureWarning, UserWarning))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_features(df, X, y, target_col=\"Y\", top_n=3, random_state=1):\n",
    "    # 1. Correlation with the target variable\n",
    "    # plt.figure(figsize=(12,8))\n",
    "    corr = df.corr()\n",
    "    # sns.heatmap(corr, annot=True)\n",
    "    # plt.show();\n",
    "    \n",
    "    scores_dicts = {}\n",
    "    top_n_dicts = {}\n",
    "    \n",
    "    corr_dict = {k: v for k, v in sorted(dict(corr[target_col].drop(target_col)).items(), key=lambda item: item[1], reverse=True)}\n",
    "    scores_dicts[\"correlation_coefficient\"] = corr_dict\n",
    "    top_n_dicts[\"correlation_coefficient\"] = list(corr_dict.keys())[:top_n]\n",
    "    \n",
    "    # 2. Information gain\n",
    "    # Information gain calculates the reduction in entropy from the transformation of a dataset.\n",
    "    # It can be used for feature selection by evaluating the Information gain of each variable \n",
    "    # in the context of the target variable.\n",
    "    info_gain_scores = mutual_info_classif(X, y)\n",
    "    info_gain = {col: info_gain_score for info_gain_score, col in zip(info_gain_scores, X.columns)}\n",
    "    info_gain_sorted = {k: v for k, v in sorted(info_gain.items(), key=lambda item: item[1], reverse=True)}\n",
    "    scores_dicts[\"information_gain\"] = info_gain_sorted\n",
    "    top_n_dicts[\"information_gain\"] = list(info_gain_sorted.keys())[:top_n]\n",
    "    \n",
    "    # 3. Fisher's score\n",
    "    # Fisher score is one of the most widely used supervised feature selection methods.\n",
    "    # The algorithm which we will use returns the ranks of the variables\n",
    "    # based on the fisher's score in descending order.\n",
    "    fisher_score_ranks = fisher_score.fisher_score(X.to_numpy(), y) +1\n",
    "    fisher_ranks = {col: fisher_score_rank for fisher_score_rank, col in zip(fisher_score_ranks, X.columns)}\n",
    "    fisher_ranks_sorted = {k: v for k, v in sorted(fisher_ranks.items(), key=lambda item: item[1])}\n",
    "    scores_dicts[\"fisher_ranks\"] = fisher_ranks_sorted\n",
    "    top_n_dicts[\"fisher_ranks\"] = list(fisher_ranks_sorted.keys())[:top_n]\n",
    "    \n",
    "    # 4. Use a simple random forest model for evaluating feature importances, etc.\n",
    "    random_forest = RandomForestClassifier(max_depth=2, random_state=random_state)\n",
    "    random_forest.fit(X, y)\n",
    "    feature_importances = random_forest.feature_importances_\n",
    "    feature_importance = {col: feature_importance for feature_importance, col in zip(feature_importances, X.columns)}\n",
    "    feature_importance_sorted = {k: v for k, v in sorted(feature_importance.items(), key=lambda item: item[1], reverse=True)}\n",
    "    scores_dicts[\"feature_importance\"] = feature_importance_sorted\n",
    "    top_n_dicts[\"feature_importance\"] = list(feature_importance_sorted.keys())[:top_n]\n",
    "    \n",
    "    scores_df = pd.DataFrame(scores_dicts)\n",
    "    top_n_df = pd.DataFrame(top_n_dicts)\n",
    "    \n",
    "    return scores_df, top_n_df\n",
    "\n",
    "\n",
    "def randomized_search(model, X_train, y_train, params, scoring=\"accuracy\", random_state=1, test_size=0.1, n_splits=1, n_iter=100):\n",
    "    sss = StratifiedShuffleSplit(random_state=random_state, test_size=test_size, n_splits=n_splits) # n_splits=10 by default\n",
    "    best_searched = RandomizedSearchCV(estimator=model, param_distributions=params, cv=sss,\n",
    "                                        scoring=scoring, random_state=random_state, n_iter=n_iter) # n_iter=10 by default\n",
    "    best_searched.fit(X_train, y_train)\n",
    "    return best_searched\n",
    "\n",
    "\n",
    "def get_mean_accuracy_scores(X, columns, n=100, random_state=1, test_size=0.1):\n",
    "    base_model=RandomForestClassifier(random_state)\n",
    "    accuracy_scores = []\n",
    "    for i in range(n):\n",
    "        _X = X[columns]\n",
    "        X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(_X, y, test_size=test_size, random_state=random_state)\n",
    "            \n",
    "        base_model.fit(X_train, y_train)\n",
    "        y_pred = base_model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracy_scores.append(accuracy)\n",
    "\n",
    "    print(f\"Mean accuracy score with columns {columns}: {round(np.mean(accuracy_scores), 2)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load data and perform EDA to understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y  X1  X2  X3  X4  X5  X6\n",
       "0  0   3   3   3   4   2   4\n",
       "1  0   3   2   3   5   4   3\n",
       "2  1   5   3   3   3   3   5\n",
       "3  0   5   4   3   3   3   5\n",
       "4  0   5   4   3   3   3   5"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df = pd.read_csv(\"./data/ACME-HappinessSurvey2020.csv\")\n",
    "survey_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Description:\n",
    "\n",
    "# Y = target attribute (Y) with values indicating 0 (unhappy) and 1 (happy) customers\n",
    "# X1 = my order was delivered on time\n",
    "# X2 = contents of my order was as I expected\n",
    "# X3 = I ordered everything I wanted to order\n",
    "# X4 = I paid a good price for my order\n",
    "# X5 = I am satisfied with my courier\n",
    "# X6 = the app makes ordering easy for me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126 entries, 0 to 125\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   Y       126 non-null    int64\n",
      " 1   X1      126 non-null    int64\n",
      " 2   X2      126 non-null    int64\n",
      " 3   X3      126 non-null    int64\n",
      " 4   X4      126 non-null    int64\n",
      " 5   X5      126 non-null    int64\n",
      " 6   X6      126 non-null    int64\n",
      "dtypes: int64(7)\n",
      "memory usage: 7.0 KB\n"
     ]
    }
   ],
   "source": [
    "survey_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.547619</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.531746</td>\n",
       "      <td>3.309524</td>\n",
       "      <td>3.746032</td>\n",
       "      <td>3.650794</td>\n",
       "      <td>4.253968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499714</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.114892</td>\n",
       "      <td>1.023440</td>\n",
       "      <td>0.875776</td>\n",
       "      <td>1.147641</td>\n",
       "      <td>0.809311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Y          X1          X2          X3          X4          X5  \\\n",
       "count  126.000000  126.000000  126.000000  126.000000  126.000000  126.000000   \n",
       "mean     0.547619    4.333333    2.531746    3.309524    3.746032    3.650794   \n",
       "std      0.499714    0.800000    1.114892    1.023440    0.875776    1.147641   \n",
       "min      0.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      0.000000    4.000000    2.000000    3.000000    3.000000    3.000000   \n",
       "50%      1.000000    5.000000    3.000000    3.000000    4.000000    4.000000   \n",
       "75%      1.000000    5.000000    3.000000    4.000000    4.000000    4.000000   \n",
       "max      1.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
       "\n",
       "               X6  \n",
       "count  126.000000  \n",
       "mean     4.253968  \n",
       "std      0.809311  \n",
       "min      1.000000  \n",
       "25%      4.000000  \n",
       "50%      4.000000  \n",
       "75%      5.000000  \n",
       "max      5.000000  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Define X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = survey_df.drop(\"Y\", axis=1)\n",
    "y = survey_df[\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Increase the number of samples by 10 times by resampling, or bootstrapping.\n",
    "\n",
    "# X_augmented = X\n",
    "# y_augmented = y\n",
    "# for i in range(9):\n",
    "#     survey_df_resampled = resample(survey_df, random_state=1)\n",
    "#     X_augmented = pd.concat([X_augmented, survey_df_resampled.drop(\"Y\", axis=1)])\n",
    "#     y_augmented = pd.concat([y_augmented, survey_df_resampled[\"Y\"]])\n",
    "\n",
    "# X = X_augmented\n",
    "# y = y_augmented"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Analyze feature importance - i.e. feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df, top_n_df = get_top_features(survey_df, X, y, top_n=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correlation_coefficient</th>\n",
       "      <th>information_gain</th>\n",
       "      <th>fisher_ranks</th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X1</th>\n",
       "      <td>0.280160</td>\n",
       "      <td>0.054141</td>\n",
       "      <td>6</td>\n",
       "      <td>0.260137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X5</th>\n",
       "      <td>0.224522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.192678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X6</th>\n",
       "      <td>0.167669</td>\n",
       "      <td>0.073935</td>\n",
       "      <td>5</td>\n",
       "      <td>0.191952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X3</th>\n",
       "      <td>0.150838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X4</th>\n",
       "      <td>0.064415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.136511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X2</th>\n",
       "      <td>-0.024274</td>\n",
       "      <td>0.056461</td>\n",
       "      <td>2</td>\n",
       "      <td>0.087870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    correlation_coefficient  information_gain  fisher_ranks  \\\n",
       "X1                 0.280160          0.054141             6   \n",
       "X5                 0.224522          0.000000             3   \n",
       "X6                 0.167669          0.073935             5   \n",
       "X3                 0.150838          0.000000             1   \n",
       "X4                 0.064415          0.000000             4   \n",
       "X2                -0.024274          0.056461             2   \n",
       "\n",
       "    feature_importance  \n",
       "X1            0.260137  \n",
       "X5            0.192678  \n",
       "X6            0.191952  \n",
       "X3            0.130852  \n",
       "X4            0.136511  \n",
       "X2            0.087870  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correlation_coefficient</th>\n",
       "      <th>information_gain</th>\n",
       "      <th>fisher_ranks</th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X1</td>\n",
       "      <td>X6</td>\n",
       "      <td>X3</td>\n",
       "      <td>X1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X5</td>\n",
       "      <td>X2</td>\n",
       "      <td>X2</td>\n",
       "      <td>X5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X6</td>\n",
       "      <td>X1</td>\n",
       "      <td>X5</td>\n",
       "      <td>X6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  correlation_coefficient information_gain fisher_ranks feature_importance\n",
       "0                      X1               X6           X3                 X1\n",
       "1                      X5               X2           X2                 X5\n",
       "2                      X6               X1           X5                 X6"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the function multiple times to take into account randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_dfs = pd.DataFrame()\n",
    "for i in range(100):\n",
    "    _, top_n_df = get_top_features(survey_df, X, y, top_n=3, random_state=1)\n",
    "    top_n_dfs = pd.concat([top_n_dfs, top_n_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X4': 30, 'X3': 140, 'X2': 149, 'X6': 257, 'X1': 281, 'X5': 343}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_occurrence = defaultdict(int)\n",
    "for i in range(len(top_n_dfs.columns)):\n",
    "    col_dict = top_n_dfs.iloc[:,i].value_counts().to_dict()\n",
    "    for k, v in col_dict.items():\n",
    "        top_n_occurrence[k] += v\n",
    "\n",
    "top_n_occurrence = dict(sorted(top_n_occurrence.items(), key=lambda item: item[1]))\n",
    "top_n_occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score with columns ['X2', 'X3', 'X4', 'X5', 'X6']: 0.51\n",
      "Mean accuracy score with columns ['X1', 'X3', 'X4', 'X5', 'X6']: 0.64\n",
      "Mean accuracy score with columns ['X1', 'X2', 'X4', 'X5', 'X6']: 0.56\n",
      "Mean accuracy score with columns ['X1', 'X2', 'X3', 'X5', 'X6']: 0.56\n",
      "Mean accuracy score with columns ['X1', 'X2', 'X3', 'X4', 'X6']: 0.51\n",
      "Mean accuracy score with columns ['X1', 'X2', 'X3', 'X4', 'X5']: 0.53\n"
     ]
    }
   ],
   "source": [
    "for col in X.columns:\n",
    "    columns = list(X.columns)\n",
    "    columns.remove(col)\n",
    "    get_mean_accuracy_scores(X, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score with columns ['X1']: 0.67\n",
      "Mean accuracy score with columns ['X2']: 0.42\n",
      "Mean accuracy score with columns ['X3']: 0.52\n",
      "Mean accuracy score with columns ['X4']: 0.5\n",
      "Mean accuracy score with columns ['X5']: 0.62\n",
      "Mean accuracy score with columns ['X6']: 0.46\n"
     ]
    }
   ],
   "source": [
    "for col in X.columns:\n",
    "    get_mean_accuracy_scores(X, [col])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the different evaluation metrics above, below would be the importance of the features:\n",
    "- High: X1, X5\n",
    "- Medium: X3, X6\n",
    "- Low: X2, X4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score with columns ['X1', 'X5']: 0.68\n",
      "Mean accuracy score with columns ['X1', 'X5', 'X3']: 0.65\n",
      "Mean accuracy score with columns ['X1', 'X5', 'X6']: 0.7\n",
      "Mean accuracy score with columns ['X1', 'X5', 'X3', 'X6']: 0.65\n"
     ]
    }
   ],
   "source": [
    "for columns in [[\"X1\", \"X5\"], [\"X1\", \"X5\", \"X3\"], [\"X1\", \"X5\", \"X6\"], [\"X1\", \"X5\", \"X3\", \"X6\"]]:\n",
    "    get_mean_accuracy_scores(X, columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features X1 and X5 resulted in the best accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1\n",
    "test_size = 0.1\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X[[\"X1\", \"X5\", \"X6\"]], y, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Try different binary classifiers to select the best performing model - i.e. model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=1) 0.7692307692307693\n",
      "AdaBoostClassifier(random_state=1) 0.5384615384615384\n",
      "GaussianNB() 0.5384615384615384\n",
      "BernoulliNB() 0.5384615384615384\n",
      "LogisticRegressionCV() 0.5384615384615384\n",
      "LinearDiscriminantAnalysis() 0.5384615384615384\n",
      "QuadraticDiscriminantAnalysis() 0.6153846153846154\n",
      "GradientBoostingClassifier(random_state=1) 0.7692307692307693\n",
      "ExtraTreesClassifier(random_state=1) 0.7692307692307693\n",
      "DecisionTreeClassifier(random_state=1) 0.6923076923076923\n",
      "SGDClassifier(random_state=1) 0.46153846153846156\n",
      "MLPClassifier(random_state=1) 0.5384615384615384\n",
      "KNeighborsClassifier() 0.6923076923076923\n",
      "\n",
      "Best model: RandomForestClassifier, Best score: 0.7692307692307693\n",
      "Best model: GradientBoostingClassifier, Best score: 0.7692307692307693\n",
      "Best model: ExtraTreesClassifier, Best score: 0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(random_state=random_state)\n",
    "ada_boost = AdaBoostClassifier(random_state=random_state)\n",
    "gaussian = GaussianNB()\n",
    "bernoulli = BernoulliNB()\n",
    "logistic_regression_cv = LogisticRegressionCV()\n",
    "linear_discriminant = LinearDiscriminantAnalysis()\n",
    "quadratic_discriminant = QuadraticDiscriminantAnalysis()\n",
    "gradient_boosting = GradientBoostingClassifier(random_state=random_state)\n",
    "extra_trees = ExtraTreesClassifier(random_state=random_state)\n",
    "decision_tree = DecisionTreeClassifier(random_state=random_state)\n",
    "sgd = SGDClassifier(random_state=random_state)\n",
    "mlp = MLPClassifier(random_state=random_state)\n",
    "k_neighbors = KNeighborsClassifier()\n",
    "\n",
    "models = [random_forest, ada_boost, gaussian, bernoulli,\n",
    "          logistic_regression_cv, linear_discriminant, quadratic_discriminant, gradient_boosting,\n",
    "          extra_trees, decision_tree, sgd, mlp, k_neighbors]\n",
    "\n",
    "best_models = []\n",
    "best_score = 0\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    if accuracy >= best_score:\n",
    "        best_score = accuracy\n",
    "        best_models.append(model)\n",
    "    print(model, accuracy)\n",
    "\n",
    "print()\n",
    "for best_model in best_models:\n",
    "    print(f\"Best model: {type(best_model).__name__}, Best score: {best_score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple classifiers without any hyperparameter tuning already exceeded the target accuracy score of 73%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Try different hyperparameters for RandomForestClassifier - i.e. hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ExtraTreesClassifier(ccp_alpha=0.01, class_weight='balanced', max_features=None,\n",
       "                      n_estimators=70, random_state=1),\n",
       " 0.8333333333333334,\n",
       " {'warm_start': False,\n",
       "  'n_estimators': 70,\n",
       "  'max_features': None,\n",
       "  'class_weight': 'balanced',\n",
       "  'ccp_alpha': 0.01})"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params = {\n",
    "#     \"n_neighbors\": np.arange(1, 10, 1),\n",
    "#     \"weights\": [\"uniform\", \"distance\"],\n",
    "#     \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "#     \"leaf_size\": np.arange(5, 50, 5),\n",
    "#     \"p\": [1, 2]\n",
    "# }\n",
    "params = {\n",
    "    \"n_estimators\": np.arange(10,200,10),\n",
    "    # \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    # \"min_weight_fraction_leaf\": np.arange(0, 1, 0.01),\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "    \"warm_start\": [True, False],\n",
    "    \"class_weight\": [\"balanced\", \"balanced_subsample\", None],\n",
    "    \"ccp_alpha\": np.arange(0, 1, 0.01)\n",
    "}\n",
    "best_searched = randomized_search(best_model, X_train, y_train, params)\n",
    "best_searched.best_estimator_, best_searched.best_score_, best_searched.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6923076923076923"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_with_best_params = best_searched.best_estimator_\n",
    "y_pred = best_model_with_best_params.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning didn't help, probably because the complexity and volume of the data were very low."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
